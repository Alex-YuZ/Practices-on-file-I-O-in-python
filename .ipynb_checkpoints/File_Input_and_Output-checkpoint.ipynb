{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pathlib` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('.')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "here = pathlib.Path('.')\n",
    "here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/alejandrosanz/Downloads')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "here.absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/alejandrosanz/Downloads')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "here.resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/alejandrosanz')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "here.resolve().parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/alejandrosanz/Downloads/projects_on_Github/POC')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "here.resolve() / 'projects_on_Github' / 'POC'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plain Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('projects_on_GitHub/POC/python_basics_and_intermediates/FIle_IO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['python programmer', 'udacity', 'web developer']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('queries.txt', 'r') as f:\n",
    "    contents = f.read()\n",
    "    \n",
    "queries = contents.split('\\n')\n",
    "norm = [i.strip().lower() for i in queries]\n",
    "norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('normalized_queries.txt', 'w') as outfile:\n",
    "    for query in norm:\n",
    "        outfile.write(query + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use writelines() method\n",
    "with open('normalized_queries1.txt', 'w') as outfile:\n",
    "    outfile.writelines('\\n'.join(norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Count unique words\n",
    "\n",
    "In this exercise, write a function count_unique_words that prints the ten most common unique words from a text file.\n",
    "```\n",
    "def count_unique_words(filename):\n",
    "    ...\n",
    "```\n",
    "Concretely, we'll be using `hamlet.txt`, a text file containing the full text of \"The Tragedy of Hamlet, Prince of Denmark\" released by Project Gutenberg under their license.\n",
    "\n",
    "We won't worry too much about punctuation, capitalization, or other nuances of language. For this exercise, it's safe to say that, given a line of text from a text file, the \"words\" within that line are the elements that result when you split the line on any whitespace.\n",
    "\n",
    "**Hint:** This will be significantly easier if you use a data type from Python's built-in `collections` module - `collections.Counter`. You can read more about `collections.Counter` [in the Python documentation](https://docs.python.org/3/library/collections.html#collections.Counter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 1109\n",
      "and 763\n",
      "of 735\n",
      "to 673\n",
      "I 514\n",
      "a 499\n",
      "in 455\n",
      "my 443\n",
      "you 423\n",
      "HAMLET. 359\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def count_unique_words(filename):\n",
    "    words = Counter()\n",
    "    with open (filename, 'r') as f:\n",
    "        for line in f:\n",
    "            words.update(line.split())\n",
    "            \n",
    "    for word, count in words.most_common(10):\n",
    "        print(word, count)\n",
    "        \n",
    "    return words\n",
    "\n",
    "result = count_unique_words('hamlet.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.json`File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo #1 -- how to read internal json-formatted data\n",
    "tmp = [\n",
    "  {\n",
    "    \"class\": \"Iris-setosa\",\n",
    "    \"petallength\": 1.4,\n",
    "    \"petalwidth\": 0.2,\n",
    "    \"sepallength\": 5.1,\n",
    "    \"sepalwidth\": 3.5\n",
    "  },\n",
    "  {\n",
    "    \"class\": \"Iris-versicolor\",\n",
    "    \"petallength\": 4.7,\n",
    "    \"petalwidth\": 1.4,\n",
    "    \"sepallength\": 7,\n",
    "    \"sepalwidth\": 3.2\n",
    "  },\n",
    "  {\n",
    "    \"class\": \"Iris-virginica\",\n",
    "    \"petallength\": 6,\n",
    "    \"petalwidth\": 2.5,\n",
    "    \"sepallength\": 6.3,\n",
    "    \"sepalwidth\": 3.3\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>petallength</th>\n",
       "      <th>petalwidth</th>\n",
       "      <th>sepallength</th>\n",
       "      <th>sepalwidth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>6.3</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             class  petallength  petalwidth  sepallength  sepalwidth\n",
       "0      Iris-setosa          1.4         0.2          5.1         3.5\n",
       "1  Iris-versicolor          4.7         1.4          7.0         3.2\n",
       "2   Iris-virginica          6.0         2.5          6.3         3.3"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data above via pd.DataFrame\n",
    "pd.DataFrame(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo #2 -- how to read a json file\n",
    "with open('top.json') as f:\n",
    "    content = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thanks, Obama.'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content['data']['children'][1]['data']['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Guardians of the Front Page',\n",
       " 'Thanks, Obama.',\n",
       " 'Take your time, you got this',\n",
       " 'Blizzard Employees Staged a Walkout After the Company Banned a Gamer for Pro-Hong Kong Views',\n",
       " 'This is Shelia Fredrick, a flight attendant. She noticed a terrified girl accompanied by an older man. She left a note in the bathroom on which the victim wrote that she needed help. The police was alerted &amp; the girl was saved from a human trafficker. We should honor our heroes.',\n",
       " 'DEMOCRACY NOW',\n",
       " 'I got a cease and desist for making the Crocs Gloves',\n",
       " 'Printers',\n",
       " 'I drew all the boys together and i did it for the internet',\n",
       " '1 dad reflex 2 children',\n",
       " 'The dog is supposed to run up in front of her and sit.',\n",
       " 'Guy Naruto Runs Past News Anchor for Storm Area 51',\n",
       " 'Tear gas canisters filmed raining in Hong Kong - against all regulations, while police deny firing from height',\n",
       " 'Protestor in Hong Kong today',\n",
       " 'This image of Xi Jiping as Winnie the Pooh is illegal in mainland China',\n",
       " 'Irish man leaves funny recording for his funeral!',\n",
       " 'This is Tiger. He just turned 31. We are told he is the oldest cat in the state of Illinois',\n",
       " 'Jeffrey Epstein, accused sex trafficker, dies by suicide: Officials',\n",
       " 'The moment this jogger realized he stumbled into my friendsâ€™ engagement photo',\n",
       " 'Simpsons predicted it yet again',\n",
       " 'ðŸŽ‰CONGRATULATIONS FELIX &amp; MARZIA ðŸŽ‰',\n",
       " 'You fell for it fool!',\n",
       " 'What a considerate man',\n",
       " 'Middle child asserting dominance over all others',\n",
       " 'Growing up, other kids used to make fun of me because I looked like the original Bob the Builder. While working in the field, they gave us these hard hats so I thought Iâ€™d take a selfie for the boys back home.']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = [i['data']['title'] for i in content['data']['children']]\n",
    "titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warm-up\n",
    "Suppose that we have the file listings.json of job listings:  \n",
    "```\n",
    "[\n",
    "    {\n",
    "        \"name\": \"Udacity\",\n",
    "        \"role\": 100,\n",
    "        \"description\": \"A stellar Python instructor is needed for a new course!\",\n",
    "        \"available\": true\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Udacity\",\n",
    "        \"role\": 404,\n",
    "        \"description\": \"A quality assistance engineer who can start immediately.\",\n",
    "        \"available\": false\n",
    "    }\n",
    "]\n",
    "\n",
    "```\n",
    "write a program that will only keep available jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data into Python\n",
    "with open('listings.json', 'r') as infile:\n",
    "    contents = json.load(infile)  # Parse JSON data into a Python object. (A)\n",
    "\n",
    "# Filter out all unavailable job listings.\n",
    "available = [job for job in contents if job[\"available\"]]\n",
    "# Write available listings to an output file.\n",
    "with open('filter-listings.json', 'w') as outfile:\n",
    "    json.dump(available, outfile, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Nobel Prizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.csv` File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_wages = []\n",
    "wage_filter = 40000\n",
    "with open('wage.csv', 'r') as infile:\n",
    "    wages = csv.reader(infile)\n",
    "    next(wages)\n",
    "    for wage in wages:\n",
    "        if int(wage[2]) >= wage_filter:\n",
    "            high_wages.append(wage)\n",
    "            \n",
    "with open('wage_filtered.csv', 'w') as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    for wage in high_wages:\n",
    "        writer.writerow(wage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use csv.DictReader() and csv.DictWriter() to keep the header\n",
    "\n",
    "The general pattern is similar to before, but there's an extra step to read data or to write data.\n",
    "\n",
    "1. Extract data from a JSON file into Python\n",
    "    - Open a file-like object `f`\n",
    "    - Create a csv.reader (or a csv.DictReader with extra information for headers)\n",
    "    - Consume each line of the csv.reader\n",
    "\n",
    "<br>\n",
    "\n",
    "2. Do something with the data, now within Python\n",
    "\n",
    "<br>\n",
    "\n",
    "3. Write data from Python to a file.\n",
    "    - Open a file-like object `f`\n",
    "    - Create a csv.writer (or a csv.DictWriter with extra information for headers)\n",
    "    - Write each line to the csv.writer\n",
    "\n",
    "<img src='working_with_csv.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('id', '200'),\n",
       "              ('title', 'Salesperson'),\n",
       "              ('annual_wage', '40000')]),\n",
       " OrderedDict([('id', '500'),\n",
       "              ('title', 'Backend Engineer'),\n",
       "              ('annual_wage', '50000')]),\n",
       " OrderedDict([('id', '512'),\n",
       "              ('title', 'Product Lead, Eng'),\n",
       "              ('annual_wage', '80000')]),\n",
       " OrderedDict([('id', '999'),\n",
       "              ('title', 'Accountant'),\n",
       "              ('annual_wage', '60000')])]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_wages = []\n",
    "wage_filter = 40000\n",
    "\n",
    "with open('wage.csv', 'r') as infile:\n",
    "    wages = csv.DictReader(infile)\n",
    "    for wage in wages:\n",
    "#         print(wage)\n",
    "        if int(wage['annual_wage']) >= wage_filter:\n",
    "            high_wages.append(wage)\n",
    "            \n",
    "\n",
    "high_wages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out\n",
    "with open('wage_filtered2.csv', 'w') as outfile:\n",
    "    wages = csv.DictWriter(outfile, fieldnames=high_wages[0].keys())\n",
    "    wages.writeheader()\n",
    "    for wage in high_wages:\n",
    "        wages.writerow(wage)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
